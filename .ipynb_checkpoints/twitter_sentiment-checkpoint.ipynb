{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84358e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\python39\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\python39\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python39\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\python39\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\python39\\lib\\site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python39\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\python39\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\python39\\lib\\site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\python39\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python39\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\python39\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python39\\lib\\site-packages (from spacy) (2.11.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\python39\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\python39\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python39\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python39\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\python39\\lib\\site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\python39\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python39\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: setuptools in c:\\python39\\lib\\site-packages (from spacy) (56.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python39\\lib\\site-packages (from spacy) (4.63.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\python39\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\python39\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\python39\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\python39\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\python39\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "%python -m spacy download en_core_web_sm\n",
    "%python -m spacy download en\n",
    "%pip install en_core_web_sm-3.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c2b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "!pip install beautifulsoup4\n",
    "%pip install textblob\n",
    "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312c985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import textblob\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from textblob import TextBlob\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f15db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244aaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_sentiment.csv',header =None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cddf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[2,3]].reset_index(drop = True)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['sentiment', 'text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a57011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "df = df[df['text'].apply(len)>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e631a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5601bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e72dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef075a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " def _get_wordcounts(x):\n",
    "\tlength = len(str(x).split())\n",
    "\treturn length\n",
    "\n",
    "def _get_charcounts(x):\n",
    "\ts = x.split()\n",
    "\tx = ''.join(s)\n",
    "\treturn len(x)\n",
    "\n",
    "def _get_avg_wordlength(x):\n",
    "\tcount = _get_charcounts(x)/_get_wordcounts(x)\n",
    "\treturn count\n",
    "\n",
    "def _get_stopwords_counts(x):\n",
    "\tl = len([t for t in x.split() if t in stopwords])\n",
    "\treturn l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_hashtag_counts(x):\n",
    "\tl = len([t for t in x.split() if t.startswith('#')])\n",
    "\treturn l\n",
    "\n",
    "def _get_mentions_counts(x):\n",
    "\tl = len([t for t in x.split() if t.startswith('@')])\n",
    "\treturn l\n",
    "\n",
    "def _get_digit_counts(x):\n",
    "\tdigits = re.findall(r'[0-9,.]+', x)\n",
    "\treturn len(digits)\n",
    "\n",
    "def _get_uppercase_counts(x):\n",
    "\treturn len([t for t in x.split() if t.isupper()])\n",
    "\n",
    "def _cont_exp(x):\n",
    "\tabbreviations = json.load(open(abbreviations_path))\n",
    "\n",
    "\tif type(x) is str:\n",
    "\t\tfor key in abbreviations:\n",
    "\t\t\tvalue = abbreviations[key]\n",
    "\t\t\traw_text = r'\\b' + key + r'\\b'\n",
    "\t\t\tx = re.sub(raw_text, value, x)\n",
    "\t\t\t# print(raw_text,value, x)\n",
    "\t\treturn x\n",
    "\telse:\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_emails(x):\n",
    "\temails = re.findall(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+\\b)', x)\n",
    "\tcounts = len(emails)\n",
    "\n",
    "\treturn counts, emails\n",
    "\n",
    "\n",
    "def _remove_emails(x):\n",
    "\treturn re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x)\n",
    "\n",
    "def _get_urls(x):\n",
    "\turls = re.findall(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', x)\n",
    "\tcounts = len(urls)\n",
    "\n",
    "\treturn counts, urls\n",
    "\n",
    "def _remove_urls(x):\n",
    "\treturn re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , x)\n",
    "\n",
    "def _remove_rt(x):\n",
    "\treturn re.sub(r'\\brt\\b', '', x).strip()\n",
    "\n",
    "def _remove_special_chars(x):\n",
    "\tx = re.sub(r'[^\\w ]+', \"\", x)\n",
    "\tx = ' '.join(x.split())\n",
    "\treturn x\n",
    "\n",
    "def _remove_html_tags(x):\n",
    "    \n",
    "\treturn BeautifulSoup(x, 'lxml').get_text().strip()\n",
    "\n",
    "def _remove_accented_chars(x):\n",
    "\tx = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\treturn x\n",
    "\n",
    "def _remove_stopwords(x):\n",
    "\treturn ' '.join([t for t in x.split() if t not in stopwords])\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_base(x):\n",
    "\tx = str(x)\n",
    "\tx_list = []\n",
    "\tdoc = nlp(x)\n",
    "\t\n",
    "\tfor token in doc:\n",
    "\t\tlemma = token.lemma_\n",
    "\t\tif lemma == '-PRON-' or lemma == 'be':\n",
    "\t\t\tlemma = token.text\n",
    "\n",
    "\t\tx_list.append(lemma)\n",
    "\treturn ' '.join(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_value_counts(df, col):\n",
    "\ttext = ' '.join(df[col])\n",
    "\ttext = text.split()\n",
    "\tfreq = pd.Series(text).value_counts()\n",
    "\treturn freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_common_words(x, freq, n=20):\n",
    "\tfn = freq[:n]\n",
    "\tx = ' '.join([t for t in x.split() if t not in fn])\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea705b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_rarewords(x, freq, n=20):\n",
    "\tfn = freq.tail(n)\n",
    "\tx = ' '.join([t for t in x.split() if t not in fn])\n",
    "\treturn x\n",
    "\n",
    "def _remove_dups_char(x):\n",
    "\tx = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "\treturn x\n",
    "\n",
    "def _spelling_correction(x):\n",
    "\tx = TextBlob(x).correct()\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e73536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_basic_features(df):\n",
    "\tif type(df) == pd.core.frame.DataFrame:\n",
    "\t\tdf['char_counts'] = df['text'].apply(lambda x: _get_charcounts(x))\n",
    "\t\tdf['word_counts'] = df['text'].apply(lambda x: _get_wordcounts(x))\n",
    "\t\tdf['avg_wordlength'] = df['text'].apply(lambda x: _get_avg_wordlength(x))\n",
    "\t\tdf['stopwords_counts'] = df['text'].apply(lambda x: _get_stopwords_counts(x))\n",
    "\t\tdf['hashtag_counts'] = df['text'].apply(lambda x: _get_hashtag_counts(x))\n",
    "\t\tdf['mentions_counts'] = df['text'].apply(lambda x: _get_mentions_counts(x))\n",
    "\t\tdf['digits_counts'] = df['text'].apply(lambda x: _get_digit_counts(x))\n",
    "\t\tdf['uppercase_counts'] = df['text'].apply(lambda x: _get_uppercase_counts(x))\n",
    "\telse:\n",
    "\t\tprint('ERROR: This function takes only Pandas DataFrame')\n",
    "\t\t\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ngram(df, col, ngram_range):\n",
    "\tvectorizer = CountVectorizer(ngram_range=(ngram_range, ngram_range))\n",
    "\tvectorizer.fit_transform(df[col])\n",
    "\tngram = vectorizer.vocabulary_\n",
    "\tngram = sorted(ngram.items(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "\treturn ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= _get_basic_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89766393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50352b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "# print (num_cols)\n",
    "\n",
    "for index, cols in enumerate(num_cols):\n",
    "    plt.subplot(2,4,index+1)\n",
    "    sns.kdeplot(data=df,x=cols, hue = 'sentiment',fill=False)\n",
    "plt.tight_layout\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts().plot(kind ='pie',autopct ='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b228c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud visualisation\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS,ImageColorGenerator\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "\n",
    "for index, col in enumerate(df['sentiment'].unique()):\n",
    "    plt.subplot(2,2, index+1)\n",
    "    # print(col)\n",
    "    df1 = df[df['sentiment']==col]\n",
    "    data = df1['text']\n",
    "    wordcloud = WordCloud(background_color='white', stopwords=stopwords, max_words=500, max_font_size=40, scale=5).generate(str(data))\n",
    "    # fig = plt.figure(figsize=(15,15))\n",
    "    # plt.axis('off')\n",
    "    # disable ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.title(col, fontsize=40)\n",
    "    \n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# lowercase, remove url, html, punctuations, retweet\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "df['text'] = df['text'].apply(lambda x: _remove_urls(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['text'] = df['text'].apply(lambda x: _remove_special_chars(x))\n",
    "df['text'] = df['text'].apply(lambda x: _remove_rt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558c125",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be255ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: _remove_html_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210edc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],df['sentiment'],test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ece007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca074eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('tfid',TfidfVectorizer() ), ('rfc',RandomForestClassifier(n_jobs=-1))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85858dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de592e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf,open(\"twitter_sentiment.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict['How the hell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8f9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
